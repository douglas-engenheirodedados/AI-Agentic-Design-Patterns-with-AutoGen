{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8140b161",
   "metadata": {},
   "source": [
    "# Lesson 2: Sequential Chats and Customer Onboarding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4d307",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24198651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "import os\n",
    "import pprint\n",
    "from autogen import ConversableAgent, UserProxyAgent\n",
    "from utils import get_azure_openai_config\n",
    "import groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a091a993",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_config = get_azure_openai_config()\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gemma2:2b\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"temperature\":2\n",
    "    },{\n",
    "        \"model\": \"llama3.2:3b\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "        \"temperature\":2\n",
    "    },{\n",
    "        \"model\": \"llama3-70b-8192\",\n",
    "        \"base_url\": \"https://api.groq.com/openai/v1\",  \n",
    "        \"api_key\": os.getenv(\"GROQ_API_KEY\"),\n",
    "        \"api_type\": \"groq\",\n",
    "        \"temperature\":1 \n",
    "    },{\n",
    "        \"model\": azure_config[\"deployment_name\"],\n",
    "        \"api_key\": azure_config[\"api_key\"],\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": azure_config[\"api_version\"],\n",
    "        \"temperature\":2\n",
    "    }\n",
    "]\n",
    "\n",
    "llm_config = {\"config_list\":config_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40dd287b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3-70b-8192',\n",
       " 'base_url': 'https://api.groq.com/openai/v1',\n",
       " 'api_key': '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',\n",
       " 'api_type': 'groq',\n",
       " 'temperature': 1}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_config['config_list'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f979f9",
   "metadata": {},
   "source": [
    "# Construindo os agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2b470c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Number Agent always returns the same numbers.\n",
    "number_agent = ConversableAgent(\n",
    "    name=\"Number_Agent\",\n",
    "    system_message=\"You return me the numbers I give you, one number each line.\",\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Adder Agent adds 1 to each number it receives.\n",
    "adder_agent = ConversableAgent(\n",
    "    name=\"Adder_Agent\",\n",
    "    system_message=\"You add 1 to each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Multiplier Agent multiplies each number it receives by 2.\n",
    "multiplier_agent = ConversableAgent(\n",
    "    name=\"Multiplier_Agent\",\n",
    "    system_message=\"You multiply each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Subtracter Agent subtracts 1 from each number it receives.\n",
    "subtracter_agent = ConversableAgent(\n",
    "    name=\"Subtracter_Agent\",\n",
    "    system_message=\"You subtract 1 from each number I give you and return me the new numbers, one number each line.\",\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")\n",
    "\n",
    "# The Divider Agent divides each number it receives by 2.\n",
    "divider_agent = ConversableAgent(\n",
    "    name=\"Divider_Agent\",\n",
    "    system_message=\"You divide each number I give you by 2 and return me the new numbers, one number each line.\",\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40da1ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Adder_Agent):\n",
      "\n",
      "14\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdder_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "15\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Adder_Agent):\n",
      "\n",
      "15\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mAdder_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "16\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Multiplier_Agent):\n",
      "\n",
      "These are my numbers\n",
      "Context: \n",
      "16\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "32\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Multiplier_Agent):\n",
      "\n",
      "32\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mMultiplier_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Subtracter_Agent):\n",
      "\n",
      "These are my numbers\n",
      "Context: \n",
      "16\n",
      "64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSubtracter_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "Here are the results of subtracting 1 from each of your numbers:\n",
      "\n",
      "15\n",
      "63\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Subtracter_Agent):\n",
      "\n",
      "Here are my numbers:\n",
      "\n",
      "15\n",
      "63\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mSubtracter_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "Here are the results of subtracting 1 from each of your numbers:\n",
      "\n",
      "14\n",
      "62\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Divider_Agent):\n",
      "\n",
      "These are my numbers\n",
      "Context: \n",
      "16\n",
      "64\n",
      "Here are the results of subtracting 1 from each of your numbers:\n",
      "\n",
      "14\n",
      "62\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mDivider_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "I'll divide each of the numbers by 2. Here are the results:\n",
      "\n",
      "7\n",
      "31\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mNumber_Agent\u001b[0m (to Divider_Agent):\n",
      "\n",
      "Here are your numbers, one per line:\n",
      "\n",
      "7\n",
      "31\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mDivider_Agent\u001b[0m (to Number_Agent):\n",
      "\n",
      "I'll divide each of the numbers by 2. Here are the results:\n",
      "\n",
      "3.5\n",
      "15.5\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start a sequence of two-agent chats.\n",
    "# Each element in the list is a dictionary that specifies the arguments\n",
    "# for the initiate_chat method.\n",
    "chat_results = number_agent.initiate_chats(\n",
    "    [\n",
    "        {\n",
    "            \"recipient\": adder_agent,\n",
    "            \"message\": \"14\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": multiplier_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": subtracter_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "        {\n",
    "            \"recipient\": divider_agent,\n",
    "            \"message\": \"These are my numbers\",\n",
    "            \"max_turns\": 2,\n",
    "            \"summary_method\": \"last_msg\",\n",
    "        },\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af43132d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Chat Summary:  16\n",
      "Second Chat Summary:  64\n",
      "Third Chat Summary:  Here are the results of subtracting 1 from each of your numbers:\n",
      "\n",
      "14\n",
      "62\n",
      "Fourth Chat Summary:  I'll divide each of the numbers by 2. Here are the results:\n",
      "\n",
      "3.5\n",
      "15.5\n"
     ]
    }
   ],
   "source": [
    "print(\"First Chat Summary: \", chat_results[0].summary)\n",
    "print(\"Second Chat Summary: \", chat_results[1].summary)\n",
    "print(\"Third Chat Summary: \", chat_results[2].summary)\n",
    "print(\"Fourth Chat Summary: \", chat_results[3].summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc4f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a527bb1e-dd4e-47b0-a1b7-a9cbcd87cbdb",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "onboarding_personal_information_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Personal_Information_Agent\",\n",
    "    system_message='''Você é um agente de onboarding de clientes, \n",
    "                    e está aqui para ajudar novos clientes a começar a usar nosso produto. \n",
    "                    Seu trabalho é coletar o nome e a localização do cliente. \n",
    "                    Não peça outras informações. \n",
    "                    Retorne 'TERMINAR' quando tiver coletado todas as informações.''',\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51bc9a24-a680-444d-943b-b740bce0189d",
   "metadata": {
    "height": 217
   },
   "outputs": [],
   "source": [
    "onboarding_topic_preference_agent = ConversableAgent(\n",
    "    name=\"Onboarding_Topic_preference_Agent\",\n",
    "    system_message='''Você é um agente de onboarding de clientes, \n",
    "                    e está aqui para ajudar novos clientes a começar a usar nosso produto. \n",
    "                    Seu trabalho é coletar as preferências de tópicos de notícias do cliente. \n",
    "                    Não peça outras informações. Retorne 'TERMINAR' quando tiver coletado todas as informações.''',\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6755a7fc-cb17-4d62-a03f-48e260f39010",
   "metadata": {
    "height": 251
   },
   "outputs": [],
   "source": [
    "customer_engagement_agent = ConversableAgent(\n",
    "    name=\"Customer_Engagement_Agent\",\n",
    "    system_message='''Você é um agente de atendimento ao cliente prestativo, \n",
    "                    e está aqui para proporcionar diversão ao cliente com base \n",
    "                    nas informações pessoais e preferências de {'topic': ''} do usuário. \n",
    "                    Isso pode incluir curiosidades, piadas ou histórias interessantes. \n",
    "                    Certifique-se de tornar isso envolvente e divertido! \n",
    "                    Retorne 'TERMINAR' quando tiver terminado.''',\n",
    "    llm_config=llm_config['config_list'][2],\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda msg: \"TERMINAR\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64267c0b-f7f2-46e6-ab44-6f7b5fbd9db7",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "customer_proxy_agent = UserProxyAgent(\n",
    "    name=\"customer_proxy_agent\",\n",
    "    llm_config=False,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"ALWAYS\",\n",
    "    is_termination_msg=lambda msg: \"TERMINAR\" in msg.get(\"content\").lower(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f240408",
   "metadata": {},
   "source": [
    "## Creating tasks\n",
    "\n",
    "Now, you can craft a series of tasks to facilitate the onboarding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b15af1d-7042-4569-a936-7966be203f05",
   "metadata": {
    "height": 608
   },
   "outputs": [],
   "source": [
    "chats = [\n",
    "    {\n",
    "        \"sender\": onboarding_personal_information_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \n",
    "            \"Olá, estou aqui para te ajudar a começar a usar nosso produto.\"\n",
    "            \"Você poderia me dizer seu nome e localização?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Retorne as informações do cliente \"\n",
    "                             \"como um objeto JSON apenas: \"\n",
    "                             \"{'name': '', 'location': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 2,\n",
    "        \"clear_history\" : True\n",
    "    },\n",
    "    {\n",
    "        \"sender\": onboarding_topic_preference_agent,\n",
    "        \"recipient\": customer_proxy_agent,\n",
    "        \"message\": \"Ótimo! Você poderia me dizer sobre quais tópicos tem interesse em ler?\",\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_args\": {\n",
    "            \"summary_prompt\" : \"Retorne as informações do cliente \"\n",
    "                             \"como um objeto JSON apenas: \"\n",
    "                             \"{'Context: ': ''}\",\n",
    "        },\n",
    "        \"max_turns\": 1,\n",
    "        \"clear_history\" : False\n",
    "    },\n",
    "    {\n",
    "        \"sender\": customer_proxy_agent,\n",
    "        \"recipient\": customer_engagement_agent,\n",
    "        \"message\": \"Vamos encontrar algo divertido para ler.\",\n",
    "        \"max_turns\": 1,\n",
    "        \"summary_method\": \"reflection_with_llm\",\n",
    "        \"summary_prompt\" : \"Passe para o agente customer_engagement_agent \"\n",
    "                             \" o contexto vindo do json do agente onboarding_topic_preference_agent\",\n",
    "        },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a066b",
   "metadata": {},
   "source": [
    "## Iniciando o chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa8f99",
   "metadata": {},
   "source": [
    "**Nota**: Você pode receber uma resposta ligeiramente diferente da que é mostrada no vídeo. Sinta-se à vontade para tentar diferentes entradas, como nome, localização e preferências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d6d1d4a-0b50-41a5-a1f0-3ff208398bc6",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Olá, estou aqui para te ajudar a começar a usar nosso produto.Você poderia me dizer seu nome e localização?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "joao\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mOnboarding_Personal_Information_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Olá Joao! Você poderia me dizer sua localização?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Personal_Information_Agent):\n",
      "\n",
      "sampa\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mOnboarding_Topic_preference_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Ótimo! Você poderia me dizer sobre quais tópicos tem interesse em ler?\n",
      "Context: \n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Onboarding_Topic_preference_Agent):\n",
      "\n",
      "cachorro\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[34mStarting a new chat....\u001b[0m\n",
      "\u001b[34m\n",
      "********************************************************************************\u001b[0m\n",
      "\u001b[33mcustomer_proxy_agent\u001b[0m (to Customer_Engagement_Agent):\n",
      "\n",
      "Vamos encontrar algo divertido para ler.\n",
      "Context: \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCustomer_Engagement_Agent\u001b[0m (to customer_proxy_agent):\n",
      "\n",
      "Olá!\n",
      "\n",
      "Oi, eu não recebi nenhuma informação sobre o seu tópico favorito, mas não se preocupe! Vamos criar algo divertido juntos!\n",
      "\n",
      "Vou começar com uma pergunta: se você pudesse viajar para qualquer lugar do mundo, onde você iria?\n",
      "\n",
      "Responda, e vamos criar uma história ou uma curiosidade divertida baseada na sua escolha!\n",
      "\n",
      "(Esqueceu-se de mencionar que tem uma piada para você em mente?)\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from autogen import initiate_chats\n",
    "\n",
    "chat_results = initiate_chats(chats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e2713",
   "metadata": {},
   "source": [
    "## Print out the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e122f8a-1ceb-4635-9672-662114b0552a",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n",
      "{'content': '', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n",
      "{'content': '', 'refusal': None, 'role': 'assistant', 'function_call': None, 'tool_calls': None}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a674c4eb",
   "metadata": {},
   "source": [
    "## Print out the cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b82a10a-afe5-4ba3-97b4-41c8c14b739f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usage_including_cached_inference': {'total_cost': 0.0010756700000000001, 'llama3-70b-8192': {'cost': 0.0010756700000000001, 'prompt_tokens': 1625, 'completion_tokens': 148, 'total_tokens': 1773}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005920299999999999, 'llama3-70b-8192': {'cost': 0.0005920299999999999, 'prompt_tokens': 899, 'completion_tokens': 78, 'total_tokens': 977}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0007248100000000001, 'llama3-70b-8192': {'cost': 0.0007248100000000001, 'prompt_tokens': 1191, 'completion_tokens': 28, 'total_tokens': 1219}}, 'usage_excluding_cached_inference': {'total_cost': 0.0007248100000000001, 'llama3-70b-8192': {'cost': 0.0007248100000000001, 'prompt_tokens': 1191, 'completion_tokens': 28, 'total_tokens': 1219}}}\n",
      "\n",
      "\n",
      "{'usage_including_cached_inference': {'total_cost': 0.0010173, 'llama3-70b-8192': {'cost': 0.0010173, 'prompt_tokens': 1115, 'completion_tokens': 455, 'total_tokens': 1570}}, 'usage_excluding_cached_inference': {'total_cost': 0.0005052, 'llama3-70b-8192': {'cost': 0.0005052, 'prompt_tokens': 555, 'completion_tokens': 225, 'total_tokens': 780}}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chat_result in chat_results:\n",
    "    print(chat_result.cost)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
